#!/usr/bin/env python3
"""
Demo: Lyra Agent Usage with UnifiedIsekAdapter
æ¼”ç¤ºï¼šä½¿ç”¨æ–°çš„UnifiedIsekAdapterä¸Lyra Agentè¿›è¡Œå®é™…çš„promptä¼˜åŒ–ä»»åŠ¡
"""

import os
import sys
import asyncio
import time
from dotenv import load_dotenv

# Add paths for imports
sys.path.append(os.path.dirname(os.path.abspath(__file__)))
sys.path.append(os.path.join(os.path.dirname(os.path.abspath(__file__)), '..'))

from isek.agent.isek_agent import IsekAgent
from isek.models.openai import OpenAIModel
from isek.tools.calculator import calculator_tools
from isek.memory.memory import Memory as SimpleMemory
from isek.team.isek_team import IsekTeam

from adapter.isek_adapter import UnifiedIsekAdapter

# Load environment variables
project_root = os.path.join(os.path.dirname(os.path.abspath(__file__)), '..')
env_path = os.path.join(project_root, '.env')
load_dotenv(env_path)


class LyraDemo:
    """Lyraæ¼”ç¤ºç±» - å±•ç¤ºå®é™…çš„promptä¼˜åŒ–åœºæ™¯"""
    
    def __init__(self):
        self.adapter = None
        self.session_id = "demo_session"
        
    def setup_lyra(self):
        """è®¾ç½®Lyraç³»ç»Ÿ"""
        print("ğŸ”§ Setting up Lyra AI Prompt Optimizer...")
        
        # åˆ›å»ºLyra Agentï¼ˆä½¿ç”¨å®Œæ•´çš„promptï¼‰
        lyra_agent = IsekAgent(
            name="Lyra-Master-Optimizer",
            model=OpenAIModel(
                model_id=os.getenv("OPENAI_MODEL_NAME", "gpt-4o-mini"),
                api_key=os.getenv("OPENAI_API_KEY"),
                base_url=os.getenv("OPENAI_BASE_URL")
            ),
            tools=[calculator_tools],
            memory=SimpleMemory(),
            description="""
You are Lyra, a master-level AI prompt optimization specialist. Your mission: transform any user input into precision-crafted prompts that unlock AI's full potential.

## OPTIMIZATION APPROACH

1. **Analyze** the user's request for clarity, specificity, and completeness
2. **Identify** gaps in context, constraints, or desired output format
3. **Enhance** with role assignment, structure, and examples when needed
4. **Deliver** optimized prompts with clear improvements explained

## RESPONSE FORMAT

**Your Optimized Prompt:**
[Improved version with specific enhancements]

**Key Improvements:**
â€¢ [List main changes and why they help]

**Pro Tip:** [Usage guidance for best results]

Always be helpful, concise, and focused on practical improvements.
            """,
            debug_mode=False
        )
        
        # åˆ›å»ºTeam
        lyra_team = IsekTeam(
            name="Lyra Prompt Optimization Team",
            description="Master-level AI prompt optimization specialists",
            members=[lyra_agent]
        )
        
        # åˆ›å»ºUnifiedIsekAdapter
        self.adapter = UnifiedIsekAdapter(
            isek_team=lyra_team,
            enable_streaming=False
        )
        
        print("âœ… Lyra system ready!")
        return True
    
    def demo_basic_optimization(self):
        """æ¼”ç¤ºåŸºç¡€promptä¼˜åŒ–"""
        print("\n" + "="*60)
        print("ğŸ“ Demo 1: Basic Prompt Optimization")
        print("="*60)
        
        # ç”¨æˆ·çš„åŸå§‹prompt
        original_prompt = "Write code for me"
        
        print(f"ğŸ’­ Original prompt: '{original_prompt}'")
        print("\nğŸ”„ Processing with Lyra...")
        
        # ä½¿ç”¨Lyraä¼˜åŒ–
        result = self.adapter.run(
            prompt=f"Please optimize this prompt: '{original_prompt}'",
            session_id=self.session_id,
            user_id="demo_user"
        )
        
        print(f"\nğŸ¯ Lyra's optimization:")
        print("-" * 40)
        print(result)
        print("-" * 40)
        
        return result
    
    async def demo_async_workflow(self):
        """æ¼”ç¤ºå¼‚æ­¥å·¥ä½œæµç¨‹"""
        print("\n" + "="*60)
        print("âš¡ Demo 2: Async Task Workflow")
        print("="*60)
        
        task_id = f"demo_task_{int(time.time())}"
        
        # æ„å»ºè¯·æ±‚ä¸Šä¸‹æ–‡
        context = {
            "task_id": task_id,
            "session_id": self.session_id,
            "user_input": "Help me create a prompt for generating creative marketing copy for a tech startup",
            "message": None,
            "current_task": None
        }
        
        print(f"ğŸ“‹ Task ID: {task_id}")
        print(f"ğŸ’¬ Request: {context['user_input']}")
        print("\nğŸ”„ Processing async...")
        
        # è·Ÿè¸ªä»»åŠ¡è¿›åº¦
        events = []
        start_time = time.time()
        
        async for event in self.adapter.execute_async(context):
            events.append(event)
            event_type = type(event).__name__
            
            if event_type == "TaskStatusUpdateEvent":
                state = event.status.state if hasattr(event, 'status') else "unknown"
                print(f"   ğŸ“Š Status: {state}")
                if hasattr(event, 'metadata') and event.metadata:
                    if 'started_at' in event.metadata:
                        print(f"   â° Started at: {event.metadata['started_at']}")
                    if 'current_step' in event.metadata:
                        print(f"   ğŸ”„ Step: {event.metadata['current_step']}")
                        
            elif event_type == "Message":
                if hasattr(event, 'parts') and event.parts:
                    for part in event.parts:
                        if hasattr(part.root, 'text'):
                            print(f"\nğŸ¯ Lyra's Response:")
                            print("-" * 40)
                            print(part.root.text)
                            print("-" * 40)
            
            # é™åˆ¶äº‹ä»¶æ•°é‡
            if len(events) >= 10:
                break
        
        duration = time.time() - start_time
        print(f"\nâœ… Task completed in {duration:.2f} seconds")
        print(f"ğŸ“ˆ Total events processed: {len(events)}")
        
        return events
    
    async def demo_multiturn_session(self):
        """æ¼”ç¤ºå¤šè½®å¯¹è¯ä¼šè¯"""
        print("\n" + "="*60)
        print("ğŸ”„ Demo 3: Multi-turn Conversation")
        print("="*60)
        
        # ç¬¬ä¸€è½®ï¼šå‘é€æ¨¡ç³Šè¯·æ±‚
        print("ğŸ”µ Round 1: Vague request")
        task_id_1 = f"multiturn_1_{int(time.time())}"
        
        context1 = {
            "task_id": task_id_1,
            "session_id": self.session_id + "_multiturn",
            "user_input": "help with email",
            "message": None,
            "current_task": None
        }
        
        print(f"ğŸ’¬ User: '{context1['user_input']}'")
        print("ğŸ”„ Lyra responding...")
        
        round1_events = []
        async for event in self.adapter.execute_async(context1):
            round1_events.append(event)
            
            if hasattr(event, 'parts') and event.parts:
                for part in event.parts:
                    if hasattr(part.root, 'text'):
                        print(f"\nğŸ¤– Lyra: {part.root.text}")
            
            if len(round1_events) >= 5:
                break
        
        # ç­‰å¾…ä¸€ä¸‹æ¨¡æ‹Ÿç”¨æˆ·æ€è€ƒ
        await asyncio.sleep(1)
        
        # ç¬¬äºŒè½®ï¼šæä¾›å…·ä½“ä¿¡æ¯
        print(f"\nğŸ”µ Round 2: Detailed follow-up")
        task_id_2 = f"multiturn_2_{int(time.time())}"
        
        context2 = {
            "task_id": task_id_2,
            "session_id": context1['session_id'],
            "user_input": "I need to write a professional email to request a meeting with potential investors for my AI startup",
            "message": None,
            "current_task": None
        }
        
        print(f"ğŸ’¬ User: '{context2['user_input']}'")
        print("ğŸ”„ Lyra responding...")
        
        round2_events = []
        async for event in self.adapter.execute_async(context2):
            round2_events.append(event)
            
            if hasattr(event, 'parts') and event.parts:
                for part in event.parts:
                    if hasattr(part.root, 'text'):
                        print(f"\nğŸ¯ Lyra: {part.root.text}")
            
            if len(round2_events) >= 5:
                break
        
        print(f"\nâœ… Multi-turn conversation completed")
        return round1_events, round2_events
    
    def demo_session_context(self):
        """æ¼”ç¤ºä¼šè¯ä¸Šä¸‹æ–‡åŠŸèƒ½"""
        print("\n" + "="*60)
        print("ğŸ’¾ Demo 4: Session Context & History")
        print("="*60)
        
        # æ˜¾ç¤ºå½“å‰ä¼šè¯å†å²
        history = self.adapter.session_manager.get_conversation_history(self.session_id)
        
        print(f"ğŸ“š Session history: {len(history)} turns")
        
        if history:
            print("\nğŸ“ Recent conversations:")
            for i, turn in enumerate(history[-3:], 1):  # æ˜¾ç¤ºæœ€è¿‘3è½®
                print(f"   {i}. User: {turn.user_input[:50]}...")
                print(f"      Agent: {turn.agent_response[:50]}...")
        
        # æµ‹è¯•ä¸Šä¸‹æ–‡æ„ŸçŸ¥
        print(f"\nğŸ§  Testing context awareness...")
        
        contextual_request = "Can you improve that last prompt even more?"
        
        result = self.adapter.run(
            prompt=contextual_request,
            session_id=self.session_id,
            user_id="demo_user"
        )
        
        print(f"ğŸ’¬ User: '{contextual_request}'")
        print(f"\nğŸ¯ Lyra (with context):")
        print("-" * 40)
        print(result)
        print("-" * 40)
        
        return result
    
    def demo_adapter_capabilities(self):
        """æ¼”ç¤ºé€‚é…å™¨èƒ½åŠ›"""
        print("\n" + "="*60)
        print("ğŸ” Demo 5: Adapter Capabilities")
        print("="*60)
        
        # è·å–é€‚é…å™¨ä¿¡æ¯
        card = self.adapter.get_adapter_card()
        
        print(f"ğŸ·ï¸  Name: {card.name}")
        print(f"ğŸ“ Bio: {card.bio}")
        print(f"ğŸ§  Knowledge: {card.knowledge}")
        print(f"âš™ï¸  Routine: {card.routine}")
        
        # æ£€æŸ¥æ”¯æŒçš„åŠŸèƒ½
        features = {
            "Streaming": self.adapter.supports_streaming(),
            "Cancellation": self.adapter.supports_cancellation(), 
            "Multi-turn": self.adapter.supports_multiturn()
        }
        
        print(f"\nğŸš€ Supported features:")
        for feature, supported in features.items():
            status = "âœ…" if supported else "âŒ"
            print(f"   {status} {feature}")
        
        return card, features


async def main():
    """ä¸»æ¼”ç¤ºå‡½æ•°"""
    print("ğŸ­ Lyra AI Prompt Optimizer Demo")
    print("="*60)
    print("Demonstrating task run and session operations with UnifiedIsekAdapter")
    print("="*60)
    
    demo = LyraDemo()
    
    try:
        # è®¾ç½®ç³»ç»Ÿ
        if not demo.setup_lyra():
            print("âŒ Failed to setup Lyra system")
            return
        
        # è¿è¡Œå„ç§æ¼”ç¤º
        print("\nğŸš€ Starting demonstrations...")
        
        # 1. åŸºç¡€ä¼˜åŒ–
        demo.demo_basic_optimization()
        
        # 2. å¼‚æ­¥å·¥ä½œæµ
        await demo.demo_async_workflow()
        
        # 3. å¤šè½®å¯¹è¯
        await demo.demo_multiturn_session()
        
        # 4. ä¼šè¯ä¸Šä¸‹æ–‡
        demo.demo_session_context()
        
        # 5. é€‚é…å™¨èƒ½åŠ›
        demo.demo_adapter_capabilities()
        
        print("\nğŸ‰ All demonstrations completed successfully!")
        print("\nğŸ“Š Summary:")
        print("â€¢ Basic prompt optimization âœ…")
        print("â€¢ Async task execution âœ…") 
        print("â€¢ Multi-turn conversations âœ…")
        print("â€¢ Session context awareness âœ…")
        print("â€¢ A2A protocol compliance âœ…")
        
    except Exception as e:
        print(f"âŒ Demo failed: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    asyncio.run(main())